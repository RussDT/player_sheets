{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df80a1f2-0ff9-4a22-a752-b1e9bdefbcff",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/index_master.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 865\u001b[0m\n\u001b[1;32m    862\u001b[0m     fig \u001b[38;5;241m=\u001b[39m create_nba_beeswarm(team,start_year,end_year,data,categories\u001b[38;5;241m=\u001b[39mcolumns,vs\u001b[38;5;241m=\u001b[39mvs,ps\u001b[38;5;241m=\u001b[39mps)\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fig\n\u001b[0;32m--> 865\u001b[0m fig \u001b[38;5;241m=\u001b[39m \u001b[43mgraph_lineupsplits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2025\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOKC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m fig\u001b[38;5;241m.\u001b[39mshow()\n",
      "Cell \u001b[0;32mIn[2], line 835\u001b[0m, in \u001b[0;36mgraph_lineupsplits\u001b[0;34m(start_year, end_year, players_on, players_off, team, vs, ps)\u001b[0m\n\u001b[1;32m    833\u001b[0m     team\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBRK\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    834\u001b[0m team_id\u001b[38;5;241m=\u001b[39mteam_dict(team)\n\u001b[0;32m--> 835\u001b[0m row\u001b[38;5;241m=\u001b[39m\u001b[43mplayer_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_year\u001b[49m\u001b[43m,\u001b[49m\u001b[43mend_year\u001b[49m\u001b[43m,\u001b[49m\u001b[43mplayers_on\u001b[49m\u001b[43m,\u001b[49m\u001b[43mplayers_off\u001b[49m\u001b[43m,\u001b[49m\u001b[43mteam_id\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mvs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m teams \u001b[38;5;241m=\u001b[39m team_averages(start_year,end_year,vs\u001b[38;5;241m=\u001b[39mvs,ps\u001b[38;5;241m=\u001b[39mps)\n\u001b[1;32m    839\u001b[0m row \u001b[38;5;241m=\u001b[39m trim_frame(row)\n",
      "Cell \u001b[0;32mIn[2], line 504\u001b[0m, in \u001b[0;36mplayer_rows\u001b[0;34m(start_year, end_year, player_ids, off_player_ids, team_id, vs, on, ps)\u001b[0m\n\u001b[1;32m    502\u001b[0m newframe[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteam_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mteam_id\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ps \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 504\u001b[0m     index\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/index_master.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     index\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/index_master_ps.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)    \n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/index_master.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nba_api.stats.static import players\n",
    "\n",
    "import time \n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import json\n",
    "import cairosvg\n",
    "import statsmodels.api as sm\n",
    "import base64\n",
    "\n",
    "from nba_api.stats.static import players,teams\n",
    "def team_dict(team):\n",
    "\n",
    "    map={'SYR': '1610612755',\n",
    "     'PHW': '1610612744',\n",
    "     'NYK': '1610612752',\n",
    "     'STL': '1610612737',\n",
    "     'ROC': '1610612758',\n",
    "     'BOS': '1610612738',\n",
    "     'FTW': '1610612765',\n",
    "     'MNL': '1610612747',\n",
    "     'TOT': 'TOT',\n",
    "     'DET': '1610612765',\n",
    "     'CIN': '1610612758',\n",
    "     'LAL': '1610612747',\n",
    "     'CHP': '1610612741',\n",
    "     'SFW': '1610612744',\n",
    "     'CHZ': '1610612741',\n",
    "     'BAL': '1610612764',\n",
    "     'PHI': '1610612755',\n",
    "     'CHI': '1610612741',\n",
    "     'SDR': '1610612745',\n",
    "     'SEA': '1610612760',\n",
    "     'MIL': '1610612749',\n",
    "     'ATL': '1610612737',\n",
    "     'PHO': '1610612756',\n",
    "     'POR': '1610612757',\n",
    "     'CLE': '1610612739',\n",
    "     'BUF': '1610612761',\n",
    "     'HOU': '1610612745',\n",
    "     'GSW': '1610612744',\n",
    "     'KCO': '1610612758',\n",
    "     'CAP': '1610612764',\n",
    "     'NOJ': '1610612762',\n",
    "     'WSB': '1610612764',\n",
    "     'KCK': '1610612758',\n",
    "     'IND': '1610612754',\n",
    "     'NYN': '1610612751',\n",
    "     'DEN': '1610612743',\n",
    "     'SAS': '1610612759',\n",
    "     'NJN': '1610612751',\n",
    "     'SDC': '1610612746',\n",
    "     'UTA': '1610612762',\n",
    "     'DAL': '1610612742',\n",
    "     'LAC': '1610612746',\n",
    "     'SAC': '1610612758',\n",
    "     'CHH': '1610612766',\n",
    "     'MIA': '1610612748',\n",
    "     'ORL': '1610612753',\n",
    "     'MIN': '1610612750',\n",
    "     'VAN': '1610612763',\n",
    "     'TOR': '1610612761',\n",
    "     'WAS': '1610612764',\n",
    "     'MEM': '1610612763',\n",
    "     'NOH': '1610612740',\n",
    "     'CHA': '1610612766',\n",
    "     'NOK': '1610612740',\n",
    "     'OKC': '1610612760',\n",
    "     'BRK': '1610612751',\n",
    "     'NOP': '1610612740',\n",
    "     'CHO': '1610612766',\n",
    "     'PHX': '1610612756'}\n",
    "    return map[team]\n",
    "\n",
    "def calculate_basketball_percentages(df):\n",
    "    \"\"\"\n",
    "    Calculate basketball percentage statistics from raw totals.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame containing the raw totals columns\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with added percentage columns\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Basic shooting percentages\n",
    "    result['Fg3Pct'] = (result['FG3M'] / result['FG3A'] * 1).fillna(0)\n",
    "    result['Fg2Pct'] = (result['FG2M'] / result['FG2A'] * 1).fillna(0)\n",
    "    result['FGA'] = (result['FG2A'] + result['FG3A'])\n",
    "    result['PenaltyFGA'] = (result['PenaltyFG2A'] + result['PenaltyFG3A'])\n",
    "    result['SecondChanceFGA'] = (result['SecondChanceFG2A'] + result['SecondChanceFG3A'])\n",
    "\n",
    "    result['FGA']= result['FG2A']+result['FG3A']\n",
    "    result['FGM']= result['FG2M']+result['FG3M']\n",
    "    result['NonHeaveFg3Pct'] = (result['FG3M'] / (result['FG3A']-result['HeaveAttempts']) * 1).fillna(0)\n",
    "    \n",
    "    # Advanced shooting percentages\n",
    "    result['EfgPct'] = ((result['FG2M'] + 1.5 * result['FG3M']) / (result['FG2A'] + result['FG3A']) * 1).fillna(0)\n",
    "    # Assuming you have a DataFrame named result with the necessary columns\n",
    "    \n",
    "    # Step 1: Extract relevant columns for easier calculations\n",
    "    points = result['Points']\n",
    "    fga = result['FGA']\n",
    "    fta = result['FTA']\n",
    "    and1_2pt = result['2pt And 1 Free Throw Trips']\n",
    "    and1_3pt = result['3pt And 1 Free Throw Trips']\n",
    "    \n",
    "    # Step 2: Calculate the adjusted free throw weighting factor\n",
    "    w = (and1_2pt + 1.5 * and1_3pt + 0.44 * (fta - and1_2pt - and1_3pt)) / fta\n",
    "    \n",
    "    # Step 3: Calculate True Shooting Percentage (TS%) and add to result DataFrame\n",
    "    result['TsPct'] = points / (2 * (fga + w * fta))\n",
    "    \n",
    "    # The 'TS%' column in the result DataFrame now contains the calculated TS% values\n",
    "\n",
    "    #result['TsPct'] = (result['Points'] / (2 * (result['FG2A'] + result['FG3A'] + 0.44 * result['FTA'])) * 1).fillna(0)\n",
    "    \n",
    "    # Second chance percentages\n",
    "    result['SecondChanceFg3Pct'] = (result['SecondChanceFG3M'] / result['SecondChanceFG3A'] * 1).fillna(0)\n",
    "    result['SecondChanceFg2Pct'] = (result['SecondChanceFG2M'] / result['SecondChanceFG2A'] * 1).fillna(0)\n",
    "    result['SecondChanceEfgPct'] = ((result['SecondChanceFG2M'] + 1.5 * result['SecondChanceFG3M']) / \n",
    "                                   (result['SecondChanceFG2A'] + result['SecondChanceFG3A']) * 1).fillna(0)\n",
    "    result['SecondChanceTsPct'] = (result['SecondChancePoints'] / \n",
    "                                  (2 * (result['SecondChanceFG2A'] + result['SecondChanceFG3A'])) * 1).fillna(0)\n",
    "\n",
    "    \n",
    "    result['SecondChancePointsPct'] = (result['SecondChancePoints'] / result['Points'] * 1).fillna(0)\n",
    "    \n",
    "    # Shot distribution\n",
    "    result['FG3APct'] = (result['FG3A'] / (result['FG2A'] + result['FG3A']) * 1).fillna(0)\n",
    "    \n",
    "    result['FG2APctBlocked'] = (result['Fg2aBlocked'] / result['FG2A'] * 1).fillna(0)\n",
    "    result['AtRimPctBlocked'] = (result['opp_BlockedAtRim'] / result['AtRimFGA'] * 1).fillna(0)\n",
    "    result['LongMidRangePctBlocked'] = (result['opp_BlockedLongMidRange'] / result['LongMidRangeFGA'] * 1).fillna(0)\n",
    "    result['ShortMidRangePctBlocked'] = (result['opp_BlockedShortMidRange'] / result['ShortMidRangeFGA'] * 1).fillna(0)\n",
    "    result['FG3APctBlocked'] = (result['Fg3aBlocked'] / result['FG3A'] * 1).fillna(0)\n",
    "    result['Corner3PctBlocked'] = (result['Blocked3s'] / result['Corner3FGA'] * 1).fillna(0)\n",
    "    result['Arc3PctBlocked'] = (result['Blocked3s'] / result['Arc3FGA'] * 1).fillna(0)\n",
    "    \n",
    "    # Rebound percentages - Field Goals (corrected to be relative to missed shots)\n",
    "    result['DefFGReboundPct'] = (result['DefRebounds'] / (result['opp_FG2A'] - result['opp_FG2M'] + result['opp_FG3A'] - result['opp_FG3M']) * 1).fillna(0)\n",
    "    result['OffFGReboundPct'] = (result['OffRebounds'] / (result['FG2A'] - result['FG2M'] + result['FG3A'] - result['FG3M']) * 1).fillna(0)\n",
    "    \n",
    "    # Rebound percentages by shot location (corrected to be relative to missed shots of that type)\n",
    "    result['OffLongMidRangeReboundPct'] = (result['OffTwoPtRebounds'] / (result['LongMidRangeFGA'] - result['LongMidRangeFGM']) * 1).fillna(0)\n",
    "    result['DefLongMidRangeReboundPct'] = (result['DefTwoPtRebounds'] / (result['LongMidRangeFGA'] - result['LongMidRangeFGM']) * 1).fillna(0)\n",
    "    result['DefArc3ReboundPct'] = (result['DefThreePtRebounds'] / (result['Arc3FGA'] - result['Arc3FGM']) * 1).fillna(0)\n",
    "    result['OffArc3ReboundPct'] = (result['OffThreePtRebounds'] / (result['Arc3FGA'] - result['Arc3FGM']) * 1).fillna(0)\n",
    "    result['DefAtRimReboundPct'] = (result['DefTwoPtRebounds'] / (result['AtRimFGA'] - result['AtRimFGM']) * 1).fillna(0)\n",
    "    result['OffAtRimReboundPct'] = (result['OffTwoPtRebounds'] / (result['AtRimFGA'] - result['AtRimFGM']) * 1).fillna(0)\n",
    "    result['DefShortMidRangeReboundPct'] = (result['DefTwoPtRebounds'] / (result['ShortMidRangeFGA'] - result['ShortMidRangeFGM']) * 1).fillna(0)\n",
    "    result['OffShortMidRangeReboundPct'] = (result['OffTwoPtRebounds'] / (result['ShortMidRangeFGA'] - result['ShortMidRangeFGM']) * 1).fillna(0)\n",
    "    result['DefCorner3ReboundPct'] = (result['DefThreePtRebounds'] / (result['Corner3FGA'] - result['Corner3FGM']) * 1).fillna(0)\n",
    "    result['OffCorner3ReboundPct'] = (result['OffThreePtRebounds'] / (result['Corner3FGA'] - result['Corner3FGM']) * 1).fillna(0)\n",
    "    \n",
    "    # Free throw rebound percentages (corrected to be relative to FT misses)\n",
    "\n",
    "    # Assist percentages\n",
    "    result['Assisted2sPct'] = (result['PtsAssisted2s'] / (2 * result['FG2M']) * 1).fillna(0)\n",
    "    result['Assisted3sPct'] = (result['PtsAssisted3s'] / (3 * result['FG3M']) * 1).fillna(0)\n",
    "    result['NonPutbacksAssisted2sPct'] = (result['PtsAssisted2s'] / (2 * (result['FG2M'] - result['PtsPutbacks']/2)) * 1).fillna(0)\n",
    "    result['Corner3PctAssisted'] = (result['Corner3Assists'] / result['Corner3FGM'] * 1).fillna(0)\n",
    "    result['Arc3PctAssisted'] = (result['Arc3Assists'] / result['Arc3FGM'] * 1).fillna(0)\n",
    "    result['SecondChanceCorner3PctAssisted'] = (result['Corner3Assists'] / result['SecondChanceCorner3FGM'] * 1).fillna(0)\n",
    "    result['SecondChanceArc3PctAssisted'] = (result['Arc3Assists'] / result['SecondChanceArc3FGM'] * 1).fillna(0)\n",
    "    result['SecondChanceAtRimPctAssisted'] = (result['AtRimAssists'] / result['SecondChanceAtRimFGM'] * 1).fillna(0)\n",
    "    result['AtRimPctAssisted'] = (result['AtRimAssists'] / result['AtRimFGM'] * 1).fillna(0)\n",
    "    result['ShortMidRangePctAssisted'] = (result['ShortMidRangeAssists'] / result['ShortMidRangeFGM'] * 1).fillna(0)\n",
    "    result['LongMidRangePctAssisted'] = (result['LongMidRangeAssists'] / result['LongMidRangeFGM'] * 1).fillna(0)\n",
    "    \n",
    "    # Penalty percentages\n",
    "    result['PenaltyPointsPct'] = (result['PenaltyPoints'] / result['Points'] * 1).fillna(0)\n",
    "    result['PenaltyOffPossPct'] = (result['PenaltyOffPoss'] / result['OffPoss'] * 1).fillna(0)\n",
    "    result['PenaltyFg2Pct'] = (result['PenaltyFG2M'] / result['PenaltyFG2A'] * 1).fillna(0)\n",
    "    result['PenaltyFg3Pct'] = (result['PenaltyFG3M'] / result['PenaltyFG3A'] * 1).fillna(0)\n",
    "    result['PenaltyEfgPct'] = ((result['PenaltyFG2M'] + 1.5 * result['PenaltyFG3M']) / \n",
    "                              (result['PenaltyFG2A'] + result['PenaltyFG3A']) * 1).fillna(0)\n",
    "    result['PenaltyTsPct'] = (result['PenaltyPoints'] / \n",
    "                             (2 * (result['PenaltyFG2A'] + result['PenaltyFG3A'] + 0.44 * result['FTA'])) * 1).fillna(0)\n",
    "    \n",
    "    # Miscellaneous percentages\n",
    "    result['BlocksRecoveredPct'] = (result['RecoveredBlocks'] / result['Blocks'] * 1).fillna(0)\n",
    "    result['LiveBallTurnoverPct'] = (result['LiveBallTurnovers'] / result['Turnovers'] * 1).fillna(0)\n",
    "    result['SelfORebPct'] = (result['SelfOReb'] /(result['FGA']- result['FGM']) * 1).fillna(0)\n",
    "    \n",
    "    # Fouls percentages\n",
    "    total_shooting_fouls = result['TwoPtShootingFoulsDrawn'] + result['ThreePtShootingFoulsDrawn']\n",
    "    result['ShootingFoulsDrawnPct'] = (result['ShootingFouls'] / (result['FG2A']+result['FG3A']) * 1).fillna(0)\n",
    "    result['TwoPtShootingFoulsDrawnPct'] = ((result['TwoPtShootingFoulsDrawn'])/ (result['FG2A']+result['2pt And 1 Free Throw Trips'])* 1).fillna(0)\n",
    "    result['ThreePtShootingFoulsDrawnPct'] = (result['ThreePtShootingFoulsDrawn'] / result['FG3A'] * 1).fillna(0)\n",
    "    total_def_rebounds = result['DefTwoPtRebounds'] + result['DefThreePtRebounds']\n",
    "    total_off_rebounds = result['OffTwoPtRebounds'] + result['OffThreePtRebounds']\n",
    "    result['ThreePtShootingFoulsDrawnPct'] = result['ThreePtShootingFoulsDrawn'] / result['FG3A'] * 1\n",
    "    \n",
    "    result['DefTwoPtReboundPct'] = (result['DefTwoPtRebounds'] / total_def_rebounds * 1).fillna(0)\n",
    "    result['DefThreePtReboundPct'] = (result['DefThreePtRebounds'] / total_def_rebounds * 1).fillna(0)\n",
    "    result['OffTwoPtReboundPct'] = (result['OffTwoPtRebounds'] /(result['FG2A']-result['FG2M']) * 1).fillna(0)\n",
    "    result['OffThreePtReboundPct'] = (result['OffThreePtRebounds'] / total_off_rebounds * 1).fillna(0)\n",
    "    \n",
    "    result['OffFTReboundPct']=(result['FTOffRebounds']/(result['opp_FTDefRebounds']+result['FTOffRebounds']))\n",
    "\n",
    "    result['DefFTReboundPct']=(result['FTDefRebounds']/(result['opp_FTOffRebounds']+result['FTDefRebounds']))\n",
    "    result['AtRimFrequency'] = result['AtRimFGA'] / result['FGA']\n",
    "    result['ShortMidRangeFrequency'] = result['ShortMidRangeFGA'] / result['FGA']\n",
    "    result['LongMidRangeFrequency'] = result['LongMidRangeFGA'] / result['FGA']\n",
    "    result['Corner3Frequency'] = result['Corner3FGA'] / result['FGA']\n",
    "    result['Arc3Frequency'] = result['Arc3FGA'] / result['FGA']\n",
    "    result['SecondChanceArc3Frequency'] = result['SecondChanceArc3FGA'] / result['SecondChanceFGA']\n",
    "    result['AtRimFG3AFrequency'] = (result['AtRimFGA'] + result['FG3A']) / result['FGA']\n",
    "    result['SecondChanceAtRimFrequency'] = result['SecondChanceAtRimFGA'] / result['SecondChanceFGA']\n",
    "    result['SecondChanceCorner3Frequency'] = result['SecondChanceCorner3FGA'] / result['SecondChanceFGA']\n",
    "    result['PenaltyAtRimFrequency'] = result['PenaltyAtRimFGA'] / result['PenaltyFGA']\n",
    "    result['PenaltyArc3Frequency'] = result['PenaltyArc3FGA'] / result['PenaltyFGA']\n",
    "    result['PenaltyCorner3Frequency'] = result['PenaltyCorner3FGA'] / result['PenaltyFGA']\n",
    "    # Calculating accuracy metrics\n",
    "    result['AtRimAccuracy'] = result['AtRimFGM'] / result['AtRimFGA']\n",
    "    result['UnblockedAtRimAccuracy'] = (result['AtRimFGM'] - result['Fg2aBlocked']) / result['AtRimFGA']\n",
    "    \n",
    "    result['ShortMidRangeAccuracy'] = result['ShortMidRangeFGM'] / result['ShortMidRangeFGA']\n",
    "    result['UnblockedShortMidRangeAccuracy'] = (result['ShortMidRangeFGM'] - result['Fg2aBlocked']) / result['ShortMidRangeFGA']\n",
    "    \n",
    "    result['LongMidRangeAccuracy'] = result['LongMidRangeFGM'] / result['LongMidRangeFGA']\n",
    "    result['UnblockedLongMidRangeAccuracy'] = (result['LongMidRangeFGM'] - result['Fg2aBlocked']) / result['LongMidRangeFGA']\n",
    "    \n",
    "    result['Corner3Accuracy'] = result['Corner3FGM'] / result['Corner3FGA']\n",
    "    result['UnblockedCorner3Accuracy'] = (result['Corner3FGM'] - result['Fg3aBlocked']) / result['Corner3FGA']\n",
    "    \n",
    "    result['Arc3Accuracy'] = result['Arc3FGM'] / result['Arc3FGA']\n",
    "    result['UnblockedArc3Accuracy'] = (result['Arc3FGM'] - result['Fg3aBlocked']) / result['Arc3FGA']\n",
    "    \n",
    "    # Second-chance accuracy metrics\n",
    "    result['SecondChanceAtRimAccuracy'] = result['SecondChanceAtRimFGM'] / result['SecondChanceAtRimFGA']\n",
    "    result['SecondChanceCorner3Accuracy'] = result['SecondChanceCorner3FGM'] / result['SecondChanceCorner3FGA']\n",
    "    result['SecondChanceArc3Accuracy'] = result['SecondChanceArc3FGM'] / result['SecondChanceArc3FGA']\n",
    "    \n",
    "    # Penalty accuracy metrics\n",
    "    result['PenaltyAtRimAccuracy'] = result['PenaltyAtRimFGM'] / result['PenaltyAtRimFGA']\n",
    "    result['PenaltyCorner3Accuracy'] = result['PenaltyCorner3FGM'] / result['PenaltyCorner3FGA']\n",
    "    result['PenaltyArc3Accuracy'] = result['PenaltyArc3FGM'] / result['PenaltyArc3FGA']\n",
    "    \n",
    "    # Non-heave accuracy metric\n",
    "    result['NonHeaveArc3Accuracy'] = result['NonHeaveArc3FGM'] / result['NonHeaveArc3FGA']\n",
    "\n",
    "\n",
    "    return result\n",
    "\n",
    "def calculate_weighted_average(df, value_col, weight_col, group_by=None):\n",
    "    \"\"\"\n",
    "    Calculate weighted average of a value column based on a weight column.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Input dataframe\n",
    "    value_col : str\n",
    "        Name of the column containing the values to average\n",
    "    weight_col : str\n",
    "        Name of the column containing the weights\n",
    "    group_by : str or list, optional\n",
    "        Column(s) to group by before calculating weighted average\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    If group_by is None: returns a float (weighted average)\n",
    "    If group_by is specified: returns a Series with weighted averages per group\n",
    "    \n",
    "    Examples:\n",
    "    --------\n",
    "    # Single weighted average\n",
    "    df = pd.DataFrame({\n",
    "        'value': [10, 20, 30],\n",
    "        'weight': [1, 2, 3]\n",
    "    })\n",
    "    result = calculate_weighted_average(df, 'value', 'weight')\n",
    "    \n",
    "    # Grouped weighted averages\n",
    "    df = pd.DataFrame({\n",
    "        'category': ['A', 'A', 'B', 'B'],\n",
    "        'value': [10, 20, 30, 40],\n",
    "        'weight': [1, 2, 3, 4]\n",
    "    })\n",
    "    result = calculate_weighted_average(df, 'value', 'weight', 'category')\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input validation\n",
    "    if value_col not in df.columns:\n",
    "        raise ValueError(f\"Value column '{value_col}' not found in dataframe\")\n",
    "    if weight_col not in df.columns:\n",
    "        raise ValueError(f\"Weight column '{weight_col}' not found in dataframe\")\n",
    "    \n",
    "    # Handle negative weights\n",
    "    if (df[weight_col] < 0).any():\n",
    "        raise ValueError(\"Negative weights found. Please ensure all weights are non-negative\")\n",
    "    \n",
    "    # Remove rows where either value or weight is null\n",
    "    df = df.dropna(subset=[value_col, weight_col])\n",
    "    \n",
    "    # If all weights are zero, return nan\n",
    "    if (df[weight_col] == 0).all():\n",
    "        print('hit zero condition')\n",
    "        return np.nan\n",
    "    \n",
    "    if group_by is None:\n",
    "        # Calculate single weighted average\n",
    "        weighted_sum = (df[value_col] * df[weight_col]).sum()\n",
    "        weight_sum = df[weight_col].sum()\n",
    "        return weighted_sum / weight_sum if weight_sum != 0 else np.nan\n",
    "    else:\n",
    "        # Calculate grouped weighted averages\n",
    "        grouped = df.groupby(group_by)\n",
    "        weighted_sums = grouped.apply(lambda x: (x[value_col] * x[weight_col]).sum())\n",
    "        weight_sums = grouped[weight_col].sum()\n",
    "        weight_sum = df[weight_col].sum()\n",
    "        return weighted_sums / weight_sum\n",
    "\n",
    "\n",
    "def transform_data(df):\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    id_col=['EntityId',\n",
    "     'TeamId',\n",
    "     'Name',\n",
    "     'ShortName',\n",
    "     'RowId',\n",
    "     'TeamAbbreviation',\n",
    "    'team_id',\n",
    "     'year',\n",
    "     'season',\n",
    "     'team_vs']\n",
    "    df['FGA']= df['FG2A']+df['FG3A']\n",
    "    df['FGM']= df['FG2M']+df['FG3M']\n",
    "    df['opp_FGA']= df['opp_FG2A']+df['opp_FG3A']\n",
    "    df['opp_FGM']= df['opp_FG2M']+df['opp_FG3M']\n",
    "\n",
    "    missing=['3pt And 1 Free Throw Trips','opp_BlockedLongMidRange','opp_FTOffRebounds']\n",
    "    for col in missing:\n",
    "        if col not in df.columns:\n",
    "            df[col]=0\n",
    "    \n",
    "    df.drop(columns=['opp_Name', 'opp_ShortName', 'opp_RowId', 'opp_TeamAbbreviation', 'opp_season'],inplace=True)\n",
    "    df['two_point_misses']= df['FG2A'] - df['FG2M']\n",
    "    df['opp_two_point_misses']= df['opp_FG2A'] - df['opp_FG2M']\n",
    "    \n",
    "    # Specific location misses\n",
    "    df['at_rim_misses']= df['AtRimFGA'] - df['AtRimFGM']\n",
    "    df['opp_at_rim_misses']= df['opp_AtRimFGA'] - df['opp_AtRimFGM']\n",
    "    \n",
    "    df['short_midrange_misses']= df['ShortMidRangeFGA'] - df['ShortMidRangeFGM']\n",
    "    \n",
    "    df['opp_short_midrange_misses']= df['opp_ShortMidRangeFGA'] - df['opp_ShortMidRangeFGM']\n",
    "    \n",
    "    df['long_midrange_misses']= df['LongMidRangeFGA'] - df['LongMidRangeFGM']\n",
    "    df['opp_long_midrange_misses']= df['opp_LongMidRangeFGA'] - df['opp_LongMidRangeFGM']\n",
    "    \n",
    "    # Three point misses by location\n",
    "    df['corner3_misses']= df['Corner3FGA'] - df['Corner3FGM']\n",
    "    df['opp_corner3_misses']= df['opp_Corner3FGA'] - df['opp_Corner3FGM']\n",
    "    \n",
    "    df['arc3_misses']= df['Arc3FGA'] - df['Arc3FGM']\n",
    "    df['opp_arc3_misses']= df['opp_Arc3FGA'] - df['opp_Arc3FGM']\n",
    "    \n",
    "    # Free throw misses\n",
    "    df['ft_misses']= df['FTA'] - df['FtPoints']\n",
    "    \n",
    "    df['opp_ft_misses']= df['opp_FTA'] - df['opp_FtPoints']\n",
    "    \n",
    "    # Total misses\n",
    "    df['fg_misses']= (df['FGA'] - df['FGM'])\n",
    "    df['opp_fg_misses']= (df['opp_FGA'] - df['opp_FGM'])\n",
    "    \n",
    "    weight_mapping = {\n",
    "        'DefTwoPtReboundPct': 'opp_two_point_misses',\n",
    "        'OffTwoPtReboundPct': 'two_point_misses',\n",
    "        'DefThreePtReboundPct':'opp_FG3A',\n",
    "        'DefFGReboundPct': 'opp_fg_misses',\n",
    "        'OffFGReboundPct': 'fg_misses',\n",
    "        'OffLongMidRangeReboundPct': 'long_midrange_misses',\n",
    "        'DefLongMidRangeReboundPct': 'opp_long_midrange_misses',\n",
    "        'OffThreePtReboundPct': 'opp_FG3A',\n",
    "        'OffArc3ReboundPct': 'arc3_misses',\n",
    "        'DefArc3ReboundPct': 'opp_arc3_misses',\n",
    "        'DefAtRimReboundPct': 'opp_at_rim_misses',\n",
    "        'DefShortMidRangeReboundPct': 'opp_short_midrange_misses',\n",
    "        'DefCorner3ReboundPct': 'opp_corner3_misses',\n",
    "        'OffAtRimReboundPct': 'at_rim_misses',\n",
    "        'SelfORebPct': 'fg_misses',\n",
    "        'OffShortMidRangeReboundPct': 'short_midrange_misses',\n",
    "        'DefFTReboundPct': 'FTDefRebounds',\n",
    "        'OffFTReboundPct':'opp_FTDefRebounds',\n",
    "        'OffCorner3ReboundPct': 'corner3_misses',\n",
    "        'SecondChanceTsPct':'SecondChanceOffPoss',\n",
    "        'SecondChanceCorner3PctAssisted':'SecondChanceCorner3FGM',\n",
    "        'SecondChanceArc3PctAssisted':'SecondChanceArc3FGM',\n",
    "        'SecondChanceAtRimPctAssisted':'SecondChanceAtRimFGM'\n",
    "    }\n",
    "    \n",
    "    # Create a DataFrame to store weighted averages for each team\n",
    "    team_weighted_avgs = pd.DataFrame()\n",
    "    \n",
    "    # Calculate weighted averages for each team\n",
    "    for team_id in df['TeamId'].unique():\n",
    "        team_data = df[df['TeamId'] == team_id]\n",
    "        team_values = {}\n",
    "        \n",
    "        for key in weight_mapping.keys():\n",
    "            if team_data[weight_mapping[key]].sum() == 0:\n",
    "                val = 0\n",
    "            else:\n",
    "                val = calculate_weighted_average(team_data, key, weight_mapping[key])\n",
    "            team_values[key] = val\n",
    "            \n",
    "        # Add team values to the DataFrame\n",
    "        team_weighted_avgs = pd.concat([\n",
    "            team_weighted_avgs, \n",
    "            pd.DataFrame([team_values], index=[team_id])\n",
    "        ])\n",
    "    \n",
    "    weight_list = list(weight_mapping.keys())\n",
    "    pct = [col for col in df.columns if 'pct' in col.lower()]\n",
    "    sum_cols = [col for col in df.columns if col not in id_col and col not in pct]\n",
    "    \n",
    "    sums = df.groupby('TeamId').sum(numeric_only=True)[sum_cols].reset_index()\n",
    "    \n",
    "    exclude = [\"PenaltyTsPct\"]\n",
    "    pct = [col for col in pct if col not in exclude]\n",
    "    pct = [col for col in pct if 'opp_' not in col.lower()]\n",
    "    \n",
    "    newframe = calculate_basketball_percentages(sums)\n",
    "    \n",
    "    # Add the weighted averages to newframe\n",
    "    for col in weight_list:\n",
    "        newframe[col] = newframe['TeamId'].map(team_weighted_avgs[col])\n",
    "    \n",
    "    to_drop = [col for col in newframe if 'opp_' in col.lower()]\n",
    "    newframe.drop(columns=to_drop, inplace=True)\n",
    "    \n",
    "    return newframe\n",
    "\n",
    "def player_rows(start_year, end_year, player_ids, off_player_ids, team_id, vs=False, on=True, ps=False):\n",
    "    pstring = \"_ps\" if ps else \"\"\n",
    "    all_df1 = []  # List to collect `df1` dataframes for each year\n",
    "    all_df2 = []  # List to collect `df2` dataframes for each year\n",
    "\n",
    "    # Loop through each year in the specified range\n",
    "    for year in range(start_year, end_year + 1):\n",
    "\n",
    "        # Load the appropriate dataframes based on the `vs` flag\n",
    "        if not vs:\n",
    "            tempdf1 = pd.read_csv(f\"https://raw.githubusercontent.com/gabriel1200/player_sheets/refs/heads/master/lineups/data/{year}/{team_id}{pstring}.csv\")\n",
    "            tempdf2 = pd.read_csv(f\"https://raw.githubusercontent.com/gabriel1200/player_sheets/refs/heads/master/lineups/data/{year}/{team_id}_vs{pstring}.csv\")\n",
    "        else:\n",
    "            tempdf2 = pd.read_csv(f\"https://raw.githubusercontent.com/gabriel1200/player_sheets/refs/heads/master/lineups/data/{year}/{team_id}{pstring}.csv\")\n",
    "            tempdf1 = pd.read_csv(f\"https://raw.githubusercontent.com/gabriel1200/player_sheets/refs/heads/master/lineups/data/{year}/{team_id}_vs{pstring}.csv\")\n",
    "\n",
    "        \n",
    "        # Append the dataframes to the lists\n",
    "        all_df1.append(tempdf1)\n",
    "        all_df2.append(tempdf2)\n",
    "\n",
    "\n",
    "    # Concatenate all yearly dataframes into one for each category\n",
    "    df1 = pd.concat(all_df1).reset_index()\n",
    "    \n",
    "    df2 = pd.concat(all_df2).reset_index()\n",
    "    # Get columns not present in df1 for default zero assignment\n",
    "    notfound = set(df2.columns) - set(df1.columns)\n",
    "    \n",
    "    # Drop the 'team_vs' column from df2 if it exists\n",
    "    if 'team_vs' in df2.columns:\n",
    "        df2.drop(columns='team_vs', inplace=True)\n",
    "    \n",
    "    # Rename columns in df2 to distinguish them in the merged dataframe\n",
    "    id_col = ['EntityId','year']\n",
    "    oppnames = [f'opp_{col}' if col not in id_col else col for col in df2.columns]\n",
    "    df2.columns = oppnames\n",
    "    \n",
    "    # Merge df1 and df2 on the 'EntityId' column\n",
    "    df = df1.merge(df2, on=id_col)\n",
    "\n",
    "    \n",
    "    # Assign 0 to missing columns from df2 in df1\n",
    "    for col in notfound:\n",
    "        df[col] = 0\n",
    "\n",
    "    # Filter rows based on the presence of any player_id in the list of player_ids\n",
    "# For players that must be in the lineup\n",
    "    if len(player_ids) > 0:\n",
    "        df = df[df['EntityId'].apply(lambda x: all(pid in x.split('-') for pid in player_ids))]\n",
    "    \n",
    "    # For players that must NOT be in the lineup\n",
    "    if len(off_player_ids) > 0:\n",
    "        df = df[df['EntityId'].apply(lambda x: not any(pid in x.split('-') for pid in off_player_ids))]\n",
    "    newframe=transform_data(df)\n",
    "\n",
    "    newframe['team_id']=team_id\n",
    "    if ps == False:\n",
    "        index=pd.read_csv('data/index_master.csv')\n",
    "    else:\n",
    "        index=pd.read_csv('data/index_master_ps.csv')    \n",
    "    index=index[index.year>=start_year]\n",
    "    index=index[index.year<=end_year]\n",
    "    name_map=dict(zip(index['nba_id'],index['player']))\n",
    "    name=''\n",
    "    names=[]\n",
    "    names2=[]\n",
    "    if player_ids:\n",
    "        for id in player_ids:\n",
    "            names.append(name_map[int(id)].split(' ')[0])\n",
    "\n",
    "    if off_player_ids:\n",
    "        for id in off_player_ids:\n",
    "            names2.append(name_map[int(id)].split(' ')[0])\n",
    "    if len(names)>0:\n",
    "                \n",
    "        name= (', ').join(names)\n",
    "        name += ' On'\n",
    "    if len(names2)>0:\n",
    "                \n",
    "        name2= (', ').join(names2)\n",
    "        name2 += ' Off'\n",
    "\n",
    "        if name =='':\n",
    "            name=name2\n",
    "        else:\n",
    "            name= name +' | ' +name2\n",
    "    \n",
    "    \n",
    "\n",
    "    newframe.drop(columns='GamesPlayed')\n",
    "    #newframe['GamesPlayed']=newframe['OffPoss']/75\n",
    "    #newframe['GamesPlayed']=newframe['GamesPlayed'].round(0)\n",
    "    newframe['Name']=name\n",
    "    \n",
    "    return newframe\n",
    "\n",
    "\n",
    "def team_averages(start_year,end_year,ps=False,vs=False):\n",
    "    carry=''\n",
    "    if ps == True:\n",
    "        carry='ps'\n",
    "    framelist=[]\n",
    "    \n",
    "    for year in range(start_year,end_year+1):\n",
    "        if vs == False:\n",
    "            df1= pd.read_csv(f\"https://raw.githubusercontent.com/gabriel1200/player_sheets/refs/heads/master/team_totals/{str(year)}{carry}.csv\")\n",
    "            df2= pd.read_csv(f\"https://raw.githubusercontent.com/gabriel1200/player_sheets/refs/heads/master/team_totals/{str(year)}vs{carry}.csv\")\n",
    "        else:\n",
    "            df2= pd.read_csv(f\"https://raw.githubusercontent.com/gabriel1200/player_sheets/refs/heads/master/team_totals/{str(year)}{carry}.csv\")\n",
    "            df1= pd.read_csv(f\"https://raw.githubusercontent.com/gabriel1200/player_sheets/refs/heads/master/team_totals/{str(year)}vs{carry}.csv\")\n",
    "        id_col = ['EntityId']\n",
    "        oppnames = [f'opp_{col}' if col not in id_col else col for col in df2.columns]\n",
    "        df2.columns = oppnames\n",
    "        \n",
    "        # Merge df1 and df2 on the 'EntityId' column\n",
    "        df = df1.merge(df2, on=id_col)\n",
    "        del df1\n",
    "        del df2\n",
    "        framelist.append(df)\n",
    "\n",
    "    teams=pd.concat(framelist)\n",
    "    namemap=dict(zip(teams['TeamId'],teams['Name']))\n",
    "        \n",
    "    teams['team_id']=teams['TeamId']\n",
    "    teams= transform_data(teams)\n",
    "    teams.drop(columns='GamesPlayed')\n",
    "    \n",
    "    teams['team_id']=teams['TeamId']\n",
    "\n",
    "\n",
    "    teams['Name']=teams['TeamId'].map(namemap)\n",
    "    teams['Minutes']= teams['SecondsPlayed']/60\n",
    "    return teams\n",
    "def trim_frame(frame1):\n",
    "    frame1['FGA']=frame1['FG2A']+frame1['FG3A']\n",
    "    frame1['TOV%'] = frame1['Turnovers'] / (frame1['OffPoss'])\n",
    "\n",
    "    columns = ['AtRimFGM','AtRimFGA','AtRimAssists','Turnovers','FTA','FGA',\n",
    "    'OffPoss','DefPoss','TwoPtAssists','Steals','BadPassSteals','TotalPoss',\n",
    "    'ThreePtAssists','FG3A','OpponentPoints','Points','SecondChancePoints','FG2A','LiveBallTurnovers']\n",
    "    other_col = ['team_id','TsPct','Fg3Pct','AtRimFG3AFrequency','Pace','AtRimFrequency','SecondsPerPossOff','SecondsPerPossDef',\n",
    "                'DefAtRimReboundPct','DefFGReboundPct','AtRimAccuracy','EfgPct','TOV%',\n",
    "'OffFGReboundPct','Name','Minutes']\n",
    "    new_df = pd.DataFrame()\n",
    "    \n",
    "\n",
    "    \n",
    "    new_df[other_col] =frame1[other_col]\n",
    "    \n",
    "\n",
    "    for col in columns:\n",
    "        if col in['OpponentPoints','DefRebounds']:\n",
    "            new_df[col]= 100* frame1[col]/frame1['DefPoss']\n",
    "\n",
    "        else:  \n",
    "            new_df[col]= 100* frame1[col]/frame1['OffPoss']\n",
    "    \n",
    "    \n",
    "    new_df = new_df.rename(columns={\n",
    "            'AtRimFrequency': 'Rim Freq',\n",
    "            'DefFGReboundPct': 'DREB%', 'OffFGReboundPct': 'OREB%', 'OpponentPoints': 'Def Rating', 'Points': 'Off Rating', 'AtRimAssists': 'Rim Assists','AtRimAccuracy': 'Rim%',\n",
    "            'ThreePtAssists': '3P Assists', 'TsPct': 'TS%', 'Fg3Pct': '3P%','EfgPct':'EFG%'})\n",
    "\n",
    "    columns = [\n",
    "            'Off Rating', 'Def Rating', 'FTA','EFG%',\n",
    "            '3P%',\n",
    "            'Rim Freq', 'TS%',\n",
    "            'Rim%',  'TOV%',\n",
    "            '3P Assists','Rim Assists',\n",
    "            'DREB%', 'OREB%','Name','Minutes']\n",
    "    return new_df[columns]\n",
    "\n",
    "def create_nba_beeswarm(team,start_year,end_year,data, categories=None,vs=False,ps=False):\n",
    "    team_names = {\n",
    "        \"PHX\": \"Phoenix Suns\",\n",
    "        \"DET\": \"Detroit Pistons\",\n",
    "        \"POR\": \"Portland Trail Blazers\",\n",
    "        \"MIL\": \"Milwaukee Bucks\",\n",
    "        \"BOS\": \"Boston Celtics\",\n",
    "        \"LAL\": \"Los Angeles Lakers\",\n",
    "        \"ORL\": \"Orlando Magic\",\n",
    "        \"NOP\": \"New Orleans Pelicans\",\n",
    "        \"NOH\": \"New Orleans Pelicans\",\n",
    "        \"DAL\": \"Dallas Mavericks\",\n",
    "        \"DEN\": \"Denver Nuggets\",\n",
    "        \"IND\": \"Indiana Pacers\",\n",
    "        \"CHA\": \"Charlotte Hornets\",\n",
    "        \"CHH\": \"Charlotte Hornets\",\n",
    "        \"SAS\": \"San Antonio Spurs\",\n",
    "        \"LAC\": \"Los Angeles Clippers\",\n",
    "        \"MEM\": \"Memphis Grizzlies\",\n",
    "        \"WAS\": \"Washington Wizards\",\n",
    "        \"MIA\": \"Miami Heat\",\n",
    "        \"ATL\": \"Atlanta Hawks\",\n",
    "        \"OKC\": \"Oklahoma City Thunder\",\n",
    "        \"SEA\": \"Seattle Supersonics\",\n",
    "        \"UTA\": \"Utah Jazz\",\n",
    "        \"NYK\": \"New York Knicks\",\n",
    "        \"CHI\": \"Chicago Bulls\",\n",
    "        \"MIN\": \"Minnesota Timberwolves\",\n",
    "        \"NJN\": \"New Jersey Nets\",\n",
    "        \"BKN\": \"Brooklyn Nets\",\n",
    "        \"BRK\": \"Brooklyn Nets\",\n",
    "        \"CLE\": \"Cleveland Cavaliers\",\n",
    "        \"HOU\": \"Houston Rockets\",\n",
    "        \"GSW\": \"Golden State Warriors\",\n",
    "        \"SAC\": \"Sacramento Kings\",\n",
    "        \"TOR\": \"Toronto Raptors\",\n",
    "        \"PHI\": \"Philadelphia 76ers\",\n",
    "        \"NOK\":\"New Orleans Pelicans\"\n",
    "    }\n",
    "    addon=''\n",
    "    if ps == True:\n",
    "        addon+= ' PS '\n",
    "    else:\n",
    "        addon+= ' RS '\n",
    "    if vs == False:\n",
    "        addon+=''\n",
    "    else:\n",
    "        addon=' (Opponents)'\n",
    "    team_name=team_names[team]\n",
    "    combo_name=data[data.lineup_row==1]['Name'].iloc[0]\n",
    "    lineup_min=data[data.lineup_row==1]['Minutes'].iloc[0]\n",
    "    opp=''\n",
    "    if vs ==True:\n",
    "        opp= ' Opp'\n",
    "    lineup_min=int(lineup_min)\n",
    "    if len(combo_name)==0:\n",
    "        combo_name=team_name+opp\n",
    "    else:\n",
    "        combo_name= team_name.split(' ')[-1] +opp+' with '+combo_name\n",
    "    combo_name= combo_name +' ('+str(lineup_min)+' min)'\n",
    "    \n",
    "    team_name+= (' '+str(start_year-1)+'-'+str(end_year))\n",
    "    \n",
    "    # Normalize the data to a 0-1 range\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_data = pd.DataFrame(\n",
    "        scaler.fit_transform(data[categories]),\n",
    "        columns=categories,\n",
    "        index=data.index\n",
    "    )\n",
    "    \n",
    "    # Separate team and lineup data\n",
    "    team_data = normalized_data[data['lineup_row'] == 0]\n",
    "    lineup_data = normalized_data[data['lineup_row'] == 1]\n",
    "    \n",
    "    # Store original values for hover text and labels\n",
    "    original_team_data = data[data['lineup_row'] == 0]\n",
    "    original_lineup_data = data[data['lineup_row'] == 1]\n",
    "    \n",
    "    # Create the figure\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Define custom colors\n",
    "    team_color = '#00ffff'\n",
    "    lineup_color = '#ff4d4d'\n",
    "    grid_color = 'rgba(255, 255, 255, 0.1)'\n",
    "    bg_color = '#1a1a1a'\n",
    "    text_color = '#ffffff'\n",
    "    \n",
    "    # Plot the actual data points\n",
    "    for i, category in enumerate(categories):\n",
    "        # Plot team data points with enhanced hover info\n",
    "        hover_texts = []\n",
    "\n",
    "        for idx in team_data.index:\n",
    "            team_abbrev = original_team_data.loc[idx, 'team']\n",
    "            team_full_name = team_names[team_abbrev]\n",
    "            value = original_team_data.loc[idx, category]\n",
    "            hover_texts.append(f\"{team_full_name}<br>{category}: {value:.1f}\")\n",
    "            \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[category] * len(team_data),\n",
    "            y=team_data[category],\n",
    "            mode='markers',\n",
    "            name='Team Season Averages per NBA Team',\n",
    "            marker=dict(\n",
    "                size=15,\n",
    "                color='#89CFF0',\n",
    "                opacity=0.7,\n",
    "                #line=dict(color='white', width=3),\n",
    "                symbol='circle'\n",
    "            ),\n",
    "            text=hover_texts,\n",
    "            hovertemplate=\"<b>%{text}</b><br>Normalized: %{y:.2f}<br><extra></extra>\",\n",
    "            showlegend=False\n",
    "        ))\n",
    "        \n",
    "        # Plot lineup data points\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[category] * len(lineup_data),\n",
    "            y=lineup_data[category],\n",
    "            mode='markers+text',\n",
    "            name=combo_name,\n",
    "            marker=dict(\n",
    "                size=21,\n",
    "                color='#8B0000',\n",
    "                opacity=1,\n",
    "                line=dict(color='#0A0A0A', width=3),\n",
    "                symbol='diamond'\n",
    "            ),\n",
    "            text=[f\"{original_lineup_data.loc[lineup, category]:.1f}\" \n",
    "                  for lineup in lineup_data.index],\n",
    "            textposition='top right',\n",
    "            textfont=dict(\n",
    "                color=text_color,\n",
    "                size=20\n",
    "            ),\n",
    "            hovertemplate=\"<b>%{text}</b><br>Normalized: %{y:.2f}<br><extra></extra>\",\n",
    "            showlegend=(i == 0)\n",
    "        ))\n",
    "    \n",
    "    # Add annotation for blue dots explanation\n",
    "    fig.add_annotation(\n",
    "        text=\"Blue dots correspond to category averages for each<br>team in the league during the selected seasons.\",\n",
    "        xref=\"paper\",\n",
    "        yref=\"paper\",\n",
    "        x=1.03,\n",
    "        y=1.05,\n",
    "        xanchor=\"right\",\n",
    "        yanchor=\"top\",\n",
    "        showarrow=False,\n",
    "        font=dict(\n",
    "            size=20,\n",
    "            color=text_color\n",
    "        ),\n",
    "        bgcolor=bg_color,\n",
    "        bordercolor=text_color,\n",
    "        borderwidth=1,\n",
    "        borderpad=2\n",
    "    )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=team_name+ addon,\n",
    "            font=dict(size=24, color=text_color),\n",
    "            x=0.5,\n",
    "            y=.99\n",
    "        ),\n",
    "        width=1600,\n",
    "        height=1000,\n",
    "        showlegend=True,\n",
    "        plot_bgcolor=bg_color,\n",
    "        paper_bgcolor=bg_color,\n",
    "        yaxis=dict(\n",
    "            title=dict(text='Normalized Value', font=dict(size=16, color=text_color)),\n",
    "            gridcolor=grid_color,\n",
    "            showgrid=False,\n",
    "            zeroline=True,\n",
    "            zerolinecolor=grid_color,\n",
    "            range=[-0.1, 1.1],\n",
    "            tickformat='.2f',\n",
    "            tickfont=dict(color=text_color),\n",
    "            tickmode='linear',\n",
    "            tick0=0,\n",
    "            dtick=0.2,\n",
    "            showticklabels=False\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            gridcolor=grid_color,\n",
    "            categoryorder='array',\n",
    "            categoryarray=categories,\n",
    "            tickfont=dict(color=text_color, size=20),\n",
    "            tickangle=-45\n",
    "        ),\n",
    "        hovermode='closest',\n",
    "        legend=dict(\n",
    "            font=dict(color=text_color,size=17),\n",
    "            bgcolor=bg_color,\n",
    "            bordercolor=bg_color,\n",
    "            borderwidth=1,\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1,\n",
    "            xanchor=\"center\",\n",
    "            x=0.2\n",
    "        ),\n",
    "        margin=dict(t=80, b=80)\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "def graph_lineupsplits(start_year,end_year,players_on,players_off,team,vs,ps):\n",
    "    if team == 'BKN':\n",
    "        team='BRK'\n",
    "    team_id=team_dict(team)\n",
    "    row=player_rows(start_year,end_year,players_on,players_off,team_id ,vs=vs,ps=ps)\n",
    "\n",
    "    teams = team_averages(start_year,end_year,vs=vs,ps=ps)\n",
    " \n",
    "    row = trim_frame(row)\n",
    "\n",
    "    teams=trim_frame(teams)\n",
    "    row['team']=team\n",
    "    teams['team']=teams['Name']\n",
    "    \n",
    "    row['lineup_row']=1\n",
    "\n",
    "    teams['lineup_row']=0\n",
    "\n",
    "    data=pd.concat([teams,row])\n",
    "    columns = [\n",
    "                'Off Rating', 'Def Rating', 'FTA',\n",
    "                '3P%',\n",
    "                'Rim Freq', 'Rim%', \n",
    "                'EFG%',\n",
    "                 'TOV%',\n",
    "              \n",
    "                'DREB%', 'OREB%']\n",
    "    exclude=['Off Rating', 'Def Rating',  '3P Assists','Rim Assists','FTA',]\n",
    "    for col in columns:\n",
    "        if col not in exclude:\n",
    "            data[col]*=100\n",
    "    fig = create_nba_beeswarm(team,start_year,end_year,data,categories=columns,vs=vs,ps=ps)\n",
    "    return fig\n",
    "\n",
    "fig = graph_lineupsplits(2024,2025,[],[],'OKC',vs=True,ps=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddba3fce-ada7-4215-89c1-3bb03c687427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
